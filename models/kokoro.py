"""
Kokoro TTS Model Loader
Fast, lightweight TTS model for local macOS
Supports multiple voice presets (male/female)
"""

import os
import torch
import numpy as np
import soundfile as sf
from pathlib import Path
import sys
import warnings
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app.device_utils import get_optimal_device, log_model_device_info

# Suppress PyTorch warnings from Kokoro model internals
warnings.filterwarnings("ignore", message="dropout option adds dropout after all but last recurrent layer", category=UserWarning)
warnings.filterwarnings("ignore", message=".*torch.nn.utils.weight_norm.*deprecated.*", category=FutureWarning)

# Kokoro model cache
MODEL_CACHE = Path("models/kokoro_cache")
VOICES_DIR = MODEL_CACHE / "voices"

# Global model instance
_kokoro_pipeline = None

def _load_kokoro_model():
    """Load Kokoro model and voices lazily."""
    global _kokoro_pipeline

    if _kokoro_pipeline is not None:
        return _kokoro_pipeline

    try:
        # Import Kokoro (assuming it's installed)
        from kokoro import KPipeline

        # Create pipeline (automatically loads model)
        pipeline = KPipeline(lang_code='a', repo_id='hexgrad/Kokoro-82M')  # American English

        # Load available voices from cache
        if VOICES_DIR.exists():
            for voice_file in VOICES_DIR.glob("*.pt"):
                voice_name = voice_file.stem  # e.g., 'af_alloy', 'am_adam', etc.
                try:
                    voice_tensor = torch.load(voice_file, weights_only=True)
                    pipeline.voices[voice_name] = voice_tensor
                except Exception as e:
                    print(f"Warning: Could not load voice {voice_name}: {e}")

        _kokoro_pipeline = pipeline
        return pipeline

    except ImportError:
        raise ImportError("Kokoro not installed. Run setup-neo-tts.sh first")
    except Exception as e:
        raise RuntimeError(f"Failed to load Kokoro model: {e}")

def _get_voice_mapping() -> dict:
    """Return mapping from formatted display names to raw voice codes."""
    return {
        # American English
        'ðŸ‡ºðŸ‡¸ Alloy ðŸšº (C)': 'af_alloy',
        'ðŸ‡ºðŸ‡¸ Aoede ðŸšº (C+)': 'af_aoede',
        'ðŸ‡ºðŸ‡¸ Bella ðŸšºðŸ”¥ (A-)': 'af_bella',
        'ðŸ‡ºðŸ‡¸ Heart ðŸšºâ¤ï¸ (A)': 'af_heart',
        'ðŸ‡ºðŸ‡¸ Jessica ðŸšº (D)': 'af_jessica',
        'ðŸ‡ºðŸ‡¸ Kore ðŸšº (C+)': 'af_kore',
        'ðŸ‡ºðŸ‡¸ Nicole ðŸšºðŸŽ§ (B-)': 'af_nicole',
        'ðŸ‡ºðŸ‡¸ Nova ðŸšº (C)': 'af_nova',
        'ðŸ‡ºðŸ‡¸ River ðŸšº (D)': 'af_river',
        'ðŸ‡ºðŸ‡¸ Sarah ðŸšº (C+)': 'af_sarah',
        'ðŸ‡ºðŸ‡¸ Sky ðŸšº (C-)': 'af_sky',

        'ðŸ‡ºðŸ‡¸ Adam ðŸš¹ (F+)': 'am_adam',
        'ðŸ‡ºðŸ‡¸ Echo ðŸš¹ (D)': 'am_echo',
        'ðŸ‡ºðŸ‡¸ Eric ðŸš¹ (D)': 'am_eric',
        'ðŸ‡ºðŸ‡¸ Fenrir ðŸš¹ (C+)': 'am_fenrir',
        'ðŸ‡ºðŸ‡¸ Liam ðŸš¹ (D)': 'am_liam',
        'ðŸ‡ºðŸ‡¸ Michael ðŸš¹ (C+)': 'am_michael',
        'ðŸ‡ºðŸ‡¸ Onyx ðŸš¹ (D)': 'am_onyx',
        'ðŸ‡ºðŸ‡¸ Puck ðŸš¹ (C+)': 'am_puck',
        'ðŸ‡ºðŸ‡¸ Santa ðŸš¹ (D-)': 'am_santa',

        # British English
        'ðŸ‡¬ðŸ‡§ Alice ðŸšº (D)': 'bf_alice',
        'ðŸ‡¬ðŸ‡§ Emma ðŸšº (B-)': 'bf_emma',
        'ðŸ‡¬ðŸ‡§ Isabella ðŸšº (C)': 'bf_isabella',
        'ðŸ‡¬ðŸ‡§ Lily ðŸšº (D)': 'bf_lily',

        'ðŸ‡¬ðŸ‡§ Daniel ðŸš¹ (D)': 'bm_daniel',
        'ðŸ‡¬ðŸ‡§ Fable ðŸš¹ (C)': 'bm_fable',
        'ðŸ‡¬ðŸ‡§ George ðŸš¹ (C)': 'bm_george',
        'ðŸ‡¬ðŸ‡§ Lewis ðŸš¹ (D+)': 'bm_lewis',

        # Japanese
        'ðŸ‡¯ðŸ‡µ Alpha ðŸšº (C+)': 'jf_alpha',
        'ðŸ‡¯ðŸ‡µ Gongitsune ðŸšº (C)': 'jf_gongitsune',
        'ðŸ‡¯ðŸ‡µ Nezumi ðŸšº (C-)': 'jf_nezumi',
        'ðŸ‡¯ðŸ‡µ Tebukuro ðŸšº (C)': 'jf_tebukuro',
        'ðŸ‡¯ðŸ‡µ Kumo ðŸš¹ (C-)': 'jm_kumo',

        # Mandarin Chinese
        'ðŸ‡¨ðŸ‡³ Xiaobei ðŸšº (D)': 'zf_xiaobei',
        'ðŸ‡¨ðŸ‡³ Xiaoni ðŸšº (D)': 'zf_xiaoni',
        'ðŸ‡¨ðŸ‡³ Xiaoxiao ðŸšº (D)': 'zf_xiaoxiao',
        'ðŸ‡¨ðŸ‡³ Xiaoyi ðŸšº (D)': 'zf_xiaoyi',
        'ðŸ‡¨ðŸ‡³ Yunjian ðŸš¹ (D)': 'zm_yunjian',
        'ðŸ‡¨ðŸ‡³ Yunxi ðŸš¹ (D)': 'zm_yunxi',
        'ðŸ‡¨ðŸ‡³ Yunxia ðŸš¹ (D)': 'zm_yunxia',
        'ðŸ‡¨ðŸ‡³ Yunyang ðŸš¹ (D)': 'zm_yunyang',

        # Spanish
        'ðŸ‡ªðŸ‡¸ Dora ðŸšº': 'ef_dora',
        'ðŸ‡ªðŸ‡¸ Alex ðŸš¹': 'em_alex',
        'ðŸ‡ªðŸ‡¸ Santa ðŸš¹': 'em_santa',

        # French
        'ðŸ‡«ðŸ‡· Siwis ðŸšº (B-)': 'ff_siwis',

        # Hindi
        'ðŸ‡®ðŸ‡³ Alpha ðŸšº (C)': 'hf_alpha',
        'ðŸ‡®ðŸ‡³ Beta ðŸšº (C)': 'hf_beta',
        'ðŸ‡®ðŸ‡³ Omega ðŸš¹ (C)': 'hm_omega',
        'ðŸ‡®ðŸ‡³ Psi ðŸš¹ (C)': 'hm_psi',

        # Italian
        'ðŸ‡®ðŸ‡¹ Sara ðŸšº (C)': 'if_sara',
        'ðŸ‡®ðŸ‡¹ Nicola ðŸš¹ (C)': 'im_nicola',

        # Brazilian Portuguese
        'ðŸ‡§ðŸ‡· Dora ðŸšº': 'pf_dora',
        'ðŸ‡§ðŸ‡· Alex ðŸš¹': 'pm_alex',
        'ðŸ‡§ðŸ‡· Santa ðŸš¹': 'pm_santa',
    }

def list_voices() -> list:
    """
    Return a list of available speakers/voices for Kokoro.
    Returns formatted voice names with flags, genders, and quality grades.
    """
    try:
        pipeline = _load_kokoro_model()
        raw_voices = list(pipeline.voices.keys())

        # Voice formatting mapping
        voice_formats = {
            # American English
            'af_alloy': 'ðŸ‡ºðŸ‡¸ Alloy ðŸšº (C)',
            'af_aoede': 'ðŸ‡ºðŸ‡¸ Aoede ðŸšº (C+)',
            'af_bella': 'ðŸ‡ºðŸ‡¸ Bella ðŸšºðŸ”¥ (A-)',
            'af_heart': 'ðŸ‡ºðŸ‡¸ Heart ðŸšºâ¤ï¸ (A)',
            'af_jessica': 'ðŸ‡ºðŸ‡¸ Jessica ðŸšº (D)',
            'af_kore': 'ðŸ‡ºðŸ‡¸ Kore ðŸšº (C+)',
            'af_nicole': 'ðŸ‡ºðŸ‡¸ Nicole ðŸšºðŸŽ§ (B-)',
            'af_nova': 'ðŸ‡ºðŸ‡¸ Nova ðŸšº (C)',
            'af_river': 'ðŸ‡ºðŸ‡¸ River ðŸšº (D)',
            'af_sarah': 'ðŸ‡ºðŸ‡¸ Sarah ðŸšº (C+)',
            'af_sky': 'ðŸ‡ºðŸ‡¸ Sky ðŸšº (C-)',

            'am_adam': 'ðŸ‡ºðŸ‡¸ Adam ðŸš¹ (F+)',
            'am_echo': 'ðŸ‡ºðŸ‡¸ Echo ðŸš¹ (D)',
            'am_eric': 'ðŸ‡ºðŸ‡¸ Eric ðŸš¹ (D)',
            'am_fenrir': 'ðŸ‡ºðŸ‡¸ Fenrir ðŸš¹ (C+)',
            'am_liam': 'ðŸ‡ºðŸ‡¸ Liam ðŸš¹ (D)',
            'am_michael': 'ðŸ‡ºðŸ‡¸ Michael ðŸš¹ (C+)',
            'am_onyx': 'ðŸ‡ºðŸ‡¸ Onyx ðŸš¹ (D)',
            'am_puck': 'ðŸ‡ºðŸ‡¸ Puck ðŸš¹ (C+)',
            'am_santa': 'ðŸ‡ºðŸ‡¸ Santa ðŸš¹ (D-)',

            # British English
            'bf_alice': 'ðŸ‡¬ðŸ‡§ Alice ðŸšº (D)',
            'bf_emma': 'ðŸ‡¬ðŸ‡§ Emma ðŸšº (B-)',
            'bf_isabella': 'ðŸ‡¬ðŸ‡§ Isabella ðŸšº (C)',
            'bf_lily': 'ðŸ‡¬ðŸ‡§ Lily ðŸšº (D)',

            'bm_daniel': 'ðŸ‡¬ðŸ‡§ Daniel ðŸš¹ (D)',
            'bm_fable': 'ðŸ‡¬ðŸ‡§ Fable ðŸš¹ (C)',
            'bm_george': 'ðŸ‡¬ðŸ‡§ George ðŸš¹ (C)',
            'bm_lewis': 'ðŸ‡¬ðŸ‡§ Lewis ðŸš¹ (D+)',

            # Japanese
            'jf_alpha': 'ðŸ‡¯ðŸ‡µ Alpha ðŸšº (C+)',
            'jf_gongitsune': 'ðŸ‡¯ðŸ‡µ Gongitsune ðŸšº (C)',
            'jf_nezumi': 'ðŸ‡¯ðŸ‡µ Nezumi ðŸšº (C-)',
            'jf_tebukuro': 'ðŸ‡¯ðŸ‡µ Tebukuro ðŸšº (C)',
            'jm_kumo': 'ðŸ‡¯ðŸ‡µ Kumo ðŸš¹ (C-)',

            # Mandarin Chinese
            'zf_xiaobei': 'ðŸ‡¨ðŸ‡³ Xiaobei ðŸšº (D)',
            'zf_xiaoni': 'ðŸ‡¨ðŸ‡³ Xiaoni ðŸšº (D)',
            'zf_xiaoxiao': 'ðŸ‡¨ðŸ‡³ Xiaoxiao ðŸšº (D)',
            'zf_xiaoyi': 'ðŸ‡¨ðŸ‡³ Xiaoyi ðŸšº (D)',
            'zm_yunjian': 'ðŸ‡¨ðŸ‡³ Yunjian ðŸš¹ (D)',
            'zm_yunxi': 'ðŸ‡¨ðŸ‡³ Yunxi ðŸš¹ (D)',
            'zm_yunxia': 'ðŸ‡¨ðŸ‡³ Yunxia ðŸš¹ (D)',
            'zm_yunyang': 'ðŸ‡¨ðŸ‡³ Yunyang ðŸš¹ (D)',

            # Spanish
            'ef_dora': 'ðŸ‡ªðŸ‡¸ Dora ðŸšº',
            'em_alex': 'ðŸ‡ªðŸ‡¸ Alex ðŸš¹',
            'em_santa': 'ðŸ‡ªðŸ‡¸ Santa ðŸš¹',

            # French
            'ff_siwis': 'ðŸ‡«ðŸ‡· Siwis ðŸšº (B-)',

            # Hindi
            'hf_alpha': 'ðŸ‡®ðŸ‡³ Alpha ðŸšº (C)',
            'hf_beta': 'ðŸ‡®ðŸ‡³ Beta ðŸšº (C)',
            'hm_omega': 'ðŸ‡®ðŸ‡³ Omega ðŸš¹ (C)',
            'hm_psi': 'ðŸ‡®ðŸ‡³ Psi ðŸš¹ (C)',

            # Italian
            'if_sara': 'ðŸ‡®ðŸ‡¹ Sara ðŸšº (C)',
            'im_nicola': 'ðŸ‡®ðŸ‡¹ Nicola ðŸš¹ (C)',

            # Brazilian Portuguese
            'pf_dora': 'ðŸ‡§ðŸ‡· Dora ðŸšº',
            'pm_alex': 'ðŸ‡§ðŸ‡· Alex ðŸš¹',
            'pm_santa': 'ðŸ‡§ðŸ‡· Santa ðŸš¹',
        }

        # Format voices, fallback to raw name if not in mapping
        formatted_voices = []
        for voice in raw_voices:
            formatted = voice_formats.get(voice, f"{voice} (Unknown)")
            formatted_voices.append(formatted)

        return formatted_voices

    except Exception:
        # Fallback to basic formatted defaults if model not loaded
        return [
            'ðŸ‡ºðŸ‡¸ Alloy ðŸšº (C)',
            'ðŸ‡ºðŸ‡¸ Adam ðŸš¹ (F+)',
            'ðŸ‡¬ðŸ‡§ Emma ðŸšº (B-)',
            'ðŸ‡¬ðŸ‡§ Daniel ðŸš¹ (D)'
        ]

def generate_audio(text: str, voice: str = None, output_path: str = "app/static/output/output.wav") -> str:
    """
    Generate audio for given text and optional voice.
    Voice parameter can be either a raw voice code (e.g., 'af_bella') or a formatted display name.
    Returns the saved file path.
    """
    if voice is None:
        voice = 'af_alloy'  # Default to American Female

    try:
        pipeline = _load_kokoro_model()

        # Convert formatted voice name to raw voice code if needed
        voice_mapping = _get_voice_mapping()
        if voice in voice_mapping:
            voice = voice_mapping[voice]  # Convert formatted name to raw code

        if voice not in pipeline.voices:
            raise ValueError(f"Voice '{voice}' not available. Available: {list(pipeline.voices.keys())}")

        # Generate audio - pipeline returns a generator yielding Result objects
        results = pipeline(text, voice=voice)

        # Collect all audio segments from the generator
        audio_segments = []
        for result in results:
            audio_segments.append(result.audio.cpu())

        # Concatenate all audio segments along time axis (dimension 0)
        if audio_segments:
            combined_audio = torch.cat(audio_segments, dim=0)
            audio_np = combined_audio.numpy()
        else:
            # Fallback if no results (shouldn't happen with valid input)
            raise RuntimeError("No audio generated from Kokoro pipeline")

        # Save the combined audio
        sf.write(output_path, audio_np, 24000)  # Kokoro uses 24kHz

        return output_path

    except Exception as e:
        raise RuntimeError(f"Kokoro generation failed: {e}")
